import pandas as pd
import joblib
import json
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import os

print("--- ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã®ç¶™ç¶šçš„å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ ---")

# --- 1. å…¨ã¦ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ ---
all_records = []
# 1-1. å…ƒã€…ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
try:
    with open('training_data.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                all_records.append(json.loads(line))
    print(f"âœ… å…ƒã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚({len(all_records)}ä»¶)")
except FileNotFoundError:
    print("[æƒ…å ±] 'training_data.jsonl' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")

# 1-2. æ–°ã—ãè“„ç©ã•ã‚ŒãŸåˆ†æçµæœã‚’èª­ã¿è¾¼ã‚€
new_knowledge_count = 0
try:
    with open('analysis_results.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                # 'analysis_results.jsonl'ã®å½¢å¼ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¤‰æ›
                analysis_data = json.loads(line)
                new_record = {
                    "log": analysis_data.get("original_log"),
                    "is_anomaly": True # åˆ†æã•ã‚ŒãŸã‚‚ã®ã¯å…¨ã¦ç•°å¸¸
                }
                all_records.append(new_record)
                new_knowledge_count += 1
    print(f"âœ… æ–°ã—ã„çŸ¥è­˜(analysis_results.jsonl)ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚({new_knowledge_count}ä»¶)")
except FileNotFoundError:
    print("[æƒ…å ±] 'analysis_results.jsonl' ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

if not all_records:
    print("[ã‚¨ãƒ©ãƒ¼] å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚")
    exit()

print(f"   => åˆè¨ˆ {len(all_records)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚")
data = pd.DataFrame(all_records)

# --- 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã¸ã®å¤‰æ› (train_model.pyã¨åŒã˜) ---
print("\n2. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AIãŒç†è§£ã§ãã‚‹æ•°å€¤ã«å¤‰æ›ä¸­...")
texts = data['log'].apply(lambda x: x.get('request_first_line', '') if isinstance(x, dict) else '').fillna("")
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)
y = data['is_anomaly']
print("   âœ… å¤‰æ›å®Œäº†ã€‚")

# --- 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰² ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\n3. ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨({len(y_train)}ä»¶)ã¨ãƒ†ã‚¹ãƒˆç”¨({len(y_test)}ä»¶)ã«åˆ†å‰²ã—ã¾ã—ãŸã€‚")

# --- 4. AIãƒ¢ãƒ‡ãƒ«ã®å†è¨“ç·´ ---
print("\n4. AIãƒ¢ãƒ‡ãƒ«ã®å†è¨“ç·´ã‚’é–‹å§‹...")
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
print("   âœ… å†è¨“ç·´å®Œäº†ï¼")

# --- 5. ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ ---
print("\n5. é€²åŒ–ã—ãŸAIãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\n   ğŸ¯ æ­£è§£ç‡ (Accuracy): {accuracy:.2f} ({accuracy*100:.2f}%)")
print("\n   è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_report(y_test, y_pred, zero_division=0))

# --- 6. é€²åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨å¤‰æ›å™¨ã§å¤ã„ã‚‚ã®ã‚’ä¸Šæ›¸ãä¿å­˜ ---
joblib.dump(model, 'log_anomaly_model.joblib')
joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')

print("--- âœ… å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")
print("é€²åŒ–ã—ãŸAIãƒ¢ãƒ‡ãƒ«ã§ 'log_anomaly_model.joblib' ã¨ 'tfidf_vectorizer.joblib' ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸã€‚")