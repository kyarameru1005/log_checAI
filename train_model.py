# --- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
import pandas as pd
import joblib
import json # jsonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç›´æ¥ä½¿ã†ãŸã‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

print("--- ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™ ---")

# --- 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ (ã‚ˆã‚Šå …ç‰¢ãªæ–¹æ³•) ---
records = []
try:
    # 1è¡Œãšã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿ã€æ‰‹å‹•ã§JSONã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
    with open('training_data.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            # ç©ºè¡Œã¯ç„¡è¦–ã™ã‚‹
            if line.strip():
                records.append(json.loads(line))
    
    # ãƒ‘ãƒ¼ã‚¹ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‹ã‚‰DataFrameã‚’ä½œæˆ
    data = pd.DataFrame(records)
    print(f"\n1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ (å…¨{len(data)}ä»¶)")

except FileNotFoundError:
    print("[ã‚¨ãƒ©ãƒ¼] 'training_data.jsonl'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚monitor.pyã§ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚")
    exit()
except json.JSONDecodeError as e:
    print(f"\n[ã‚¨ãƒ©ãƒ¼] 'training_data.jsonl'ã®èª­ã¿è¾¼ã¿ä¸­ã«JSONã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç ´æè¡Œã®è¿‘ãã§ã‚¨ãƒ©ãƒ¼: {e}")
    print("ä¸€åº¦ 'training_data.jsonl' ã‚’å‰Šé™¤ã—ã€å†åº¦ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    exit()


# --- 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã¸ã®å¤‰æ› ---
print("\n2. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AIãŒç†è§£ã§ãã‚‹æ•°å€¤ã«å¤‰æ›ä¸­...")
# å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ1è¡Œç›®ã‚’æŠ½å‡ºã—ã€ç©ºæ¬„ã¯ç©ºæ–‡å­—åˆ—ã§åŸ‹ã‚ã‚‹
texts = data['log'].apply(lambda x: x.get('request_first_line', '')).fillna("")
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(texts)
y = data['is_anomaly']
print("   âœ… å¤‰æ›å®Œäº†ã€‚")

# --- 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰² ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\n3. ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨({len(y_train)}ä»¶)ã¨ãƒ†ã‚¹ãƒˆç”¨({len(y_test)}ä»¶)ã«åˆ†å‰²ã—ã¾ã—ãŸã€‚")

# --- 4. AIãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ---
print("\n4. AIãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰ã®è¨“ç·´ã‚’é–‹å§‹...")
# max_iterã‚’å¢—ã‚„ã—ã¦åæŸã—ã‚„ã™ãã™ã‚‹
model = LogisticRegression(max_iter=1000) # åæŸã—ã‚„ã™ãã™ã‚‹ãŸã‚ã«max_iterã‚’å¢—ã‚„ã™
model.fit(X_train, y_train)
print("   âœ… è¨“ç·´å®Œäº†ï¼")

# --- 5. ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ ---
print("\n5. å®Œæˆã—ãŸAIãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã¾ã™ã€‚")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\n   ğŸ¯ æ­£è§£ç‡ (Accuracy): {accuracy:.2f} ({accuracy*100:.2f}%)")
print("\n   è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ:")
# zero_division=0 ã‚’è¿½åŠ ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã®è­¦å‘Šã‚’æŠ‘åˆ¶
print(classification_report(y_test, y_pred, zero_division=0))

# --- 6. å®Œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã¨å¤‰æ›å™¨ã®ä¿å­˜ ---
# è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
joblib.dump(model, 'log_anomaly_model.joblib')
joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')

print("\n--- âœ… å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")
print(" 'log_anomaly_model.joblib' ã¨ 'tfidf_vectorizer.joblib' ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")