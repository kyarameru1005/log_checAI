import time
import joblib
import subprocess
import json
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import apache_log_parser
from pprint import pprint

# --- Configuration (è¨­å®š) ---
WATCH_DIR = "/var/log/apache2"
LOG_FORMAT = "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\""
parser = apache_log_parser.make_parser(LOG_FORMAT)
ANALYSIS_FILE = "analysis_results.jsonl"

class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime): return obj.isoformat()
        return super().default(obj)

# --- 1. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ ---
BLACKLISTED_PATTERNS = [
    "/.env", "/.git", "/wp-config.php", "etc/passwd",
    "SELECT", "UNION", "INSERT", "<script>", "/geoserver/",
]

def is_anomaly_by_rule(request_line):
    for pattern in BLACKLISTED_PATTERNS:
        if pattern.lower() in request_line.lower(): return True
    return False

# --- 2. è¨“ç·´æ¸ˆã¿AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
try:
    print("--- è¨“ç·´æ¸ˆã¿AIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™... ---")
    model = joblib.load('log_anomaly_model.joblib')
    vectorizer = joblib.load('tfidf_vectorizer.joblib')
    print("   âœ… AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™å®Œäº†ã€‚")
except FileNotFoundError:
    print("[ã‚¨ãƒ©ãƒ¼] AIãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    exit()

# --- 3. AIã«ã‚ˆã‚‹äºˆæ¸¬é–¢æ•° ---
def predict_log_anomaly(log_text):
    vectorized_text = vectorizer.transform([log_text])
    prediction = model.predict(vectorized_text)[0]
    return bool(prediction)

# --- åˆ†æã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹èµ·å‹•ã€œè¨˜éŒ²ï¼‰---
def trigger_analysis_sequence(log_data, detection_method):
    print(f"--- ğŸš€ åˆ†æã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹ (æ¤œçŸ¥æ–¹æ³•: {detection_method}) ---")
    # (ã“ã®é–¢æ•°ã®ä¸­èº«ã¯å¤‰æ›´ãªã—)
    container_id = None
    try:
        print("1. Apacheã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’èµ·å‹•ä¸­...")
        command = ["docker", "run", "-d", "--rm", "twinai-apache-sandbox"]
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        container_id = result.stdout.strip()
        print(f"   âœ… èµ·å‹•æˆåŠŸ (ã‚³ãƒ³ãƒ†ãƒŠID: {container_id[:12]})")
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã®èµ·å‹•ã«å¤±æ•—: {e}")
        return

    reproduce_output, filesystem_changes = "", ""
    try:
        print(f"\n2. ã‚³ãƒ³ãƒ†ãƒŠã«å¯¾ã—ã¦æ”»æ’ƒã‚’å†ç¾ä¸­...")
        request_path = log_data.get('request_first_line', '').split()[1]
        reproduce_command = ["docker", "exec", container_id, "curl", f"http://localhost:80{request_path}"]
        reproduce_result = subprocess.run(reproduce_command, capture_output=True, text=True, check=False)
        reproduce_output = reproduce_result.stdout.strip() if reproduce_result.stdout else reproduce_result.stderr.strip()
        print("   âœ… å†ç¾å®Œäº†ã€‚")
    except Exception as e:
        reproduce_output = f"å†ç¾ã‚¨ãƒ©ãƒ¼: {e}"

    try:
        print("\n3. ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®å¤‰åŒ–ã‚’è¦³å¯Ÿä¸­...")
        diff_command = ["docker", "diff", container_id]
        diff_result = subprocess.run(diff_command, capture_output=True, text=True, check=True)
        filesystem_changes = diff_result.stdout.strip()
        print("   âœ… è¦³å¯Ÿå®Œäº†ã€‚")
    except Exception as e:
        filesystem_changes = f"å·®åˆ†æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼: {e}"

    try:
        print(f"\n4. åˆ†æçµæœã‚’ {ANALYSIS_FILE} ã«è¨˜éŒ²ä¸­...")
        analysis_record = {
            "analysis_timestamp": datetime.now().isoformat(),
            "detection_method": detection_method,
            "original_log": log_data,
            "reproduction_result": reproduce_output,
            "filesystem_changes": filesystem_changes.split('\n') if filesystem_changes else []
        }
        with open(ANALYSIS_FILE, "a") as f:
            f.write(json.dumps(analysis_record, cls=DateTimeEncoder) + "\n")
        print("   âœ… è¨˜éŒ²å®Œäº†ã€‚")
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] çµæœã®è¨˜éŒ²ã«å¤±æ•—: {e}")

    finally:
        if container_id:
            print("\n5. ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’ç ´æ£„ã—ã¾ã™ã€‚")
            subprocess.run(["docker", "stop", container_id], capture_output=True, text=True)

# --- â˜…â˜…â˜… ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’ä¿®æ­£ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ãƒãƒ³ãƒ‰ãƒ© â˜…â˜…â˜… ---
class ChangeHandler(FileSystemEventHandler):
    def __init__(self):
        self.last_positions = {}

    def on_modified(self, event):
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å¤‰æ›´ã‚„ã€access.logä»¥å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç„¡è¦–
        if event.is_directory or 'access.log' not in event.src_path:
            return

        # ã‚¹ãƒ†ãƒƒãƒ—1: æ–°ã—ã„è¡Œã‚’ç¢ºå®Ÿã«èª­ã¿è¾¼ã¿ã€èª­ã¿çµ‚ã‚ã£ãŸå ´æ‰€ã‚’è¨˜æ†¶ã™ã‚‹
        new_lines = []
        try:
            with open(event.src_path, 'r', encoding='utf-8') as f:
                # å‰å›èª­ã¿çµ‚ã‚ã£ãŸå ´æ‰€ã‹ã‚‰é–‹å§‹
                f.seek(self.last_positions.get(event.src_path, 0))
                new_lines = f.readlines()
                # èª­ã¿çµ‚ã‚ã£ãŸä½ç½®ã‚’ã™ãã«æ›´æ–°ã™ã‚‹ï¼ˆã“ã‚ŒãŒé‡è¦ï¼ï¼‰
                self.last_positions[event.src_path] = f.tell()
        except Exception as e:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return # èª­ã¿è¾¼ã‚ãªã„å ´åˆã¯ã€ä»Šå›ã¯ä½•ã‚‚ã—ãªã„

        if not new_lines:
            return # æ–°ã—ã„è¡ŒãŒãªã‘ã‚Œã°çµ‚äº†

        # ã‚¹ãƒ†ãƒƒãƒ—2: èª­ã¿è¾¼ã‚“ã æ–°ã—ã„è¡Œã ã‘ã‚’å‡¦ç†ã™ã‚‹
        for line in new_lines:
            if not line.strip():
                continue
            
            try:
                log_data = parser(line)
                request_line = log_data.get('request_first_line', '')
                
                # ãƒ«ãƒ¼ãƒ«ã¾ãŸã¯AIã§ç•°å¸¸ã‚’æ¤œçŸ¥
                if is_anomaly_by_rule(request_line):
                    print("\nğŸš¨ğŸš¨ğŸš¨ã€ãƒ«ãƒ¼ãƒ«ã§ç•°å¸¸ã‚’æ¤œçŸ¥ã€‘ğŸš¨ğŸš¨ğŸš¨")
                    pprint(log_data)
                    trigger_analysis_sequence(log_data, "Rule-based")
                elif predict_log_anomaly(request_line):
                    print("\nğŸš¨ğŸš¨ğŸš¨ã€AIãŒç•°å¸¸ã‚’æ¤œçŸ¥ã€‘ğŸš¨ğŸš¨ğŸš¨")
                    pprint(log_data)
                    trigger_analysis_sequence(log_data, "AI-based")

            except Exception as e:
                # ç‰¹å®šã®è¡Œã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¦ã‚‚ã€ä»–ã®è¡Œã®å‡¦ç†ã¯ç¶šã‘ã‚‹
                print(f"[è­¦å‘Š] ãƒ­ã‚°1è¡Œã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    print("\n--- TwinAI - Log Sentinel (v1.1 å®‰å®šç‰ˆ) èµ·å‹• ---")
    event_handler = ChangeHandler()
    observer = Observer()
    observer.schedule(event_handler, WATCH_DIR, recursive=True)
    observer.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
        print("\n--- ç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™ ---")
    observer.join()