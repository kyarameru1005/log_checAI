import time
import subprocess
import json
from datetime import datetime # æ—¥æ™‚ã‚’æ‰±ã†ãŸã‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import apache_log_parser
from pprint import pprint

# --- Configuration ---
WATCH_DIR = "/var/log/apache2"
LOG_FORMAT = "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\""
parser = apache_log_parser.make_parser(LOG_FORMAT)
ANALYSIS_FILE = "analysis_results.jsonl"

# --- Anomaly Detection Rule ---
def is_anomaly(log_data):
    try:
        status = int(log_data['status'])
        if status >= 400:
            return True
    except (ValueError, KeyError):
        return False
    return False

# --- Analysis Sequence ---
def trigger_analysis_sequence(log_data):
    print("\n--- ğŸš€ åˆ†æã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹ ---")
    
    container_id = None
    try:
        print("1. Apacheã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’èµ·å‹•ä¸­...")
        command = ["docker", "run", "-d", "--rm", "twinai-apache-sandbox"]
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        container_id = result.stdout.strip()
        print(f"   âœ… èµ·å‹•æˆåŠŸ (ã‚³ãƒ³ãƒ†ãƒŠID: {container_id[:12]})")
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    reproduce_output = ""
    try:
        print(f"\n2. ã‚³ãƒ³ãƒ†ãƒŠ {container_id[:12]} ã«å¯¾ã—ã¦æ”»æ’ƒã‚’å†ç¾ä¸­...")
        request_path = log_data.get('request_first_line', '').split()[1]
        reproduce_command = ["docker", "exec", container_id, "curl", f"http://localhost:80{request_path}"]
        reproduce_result = subprocess.run(reproduce_command, capture_output=True, text=True, check=False)
        reproduce_output = reproduce_result.stdout if reproduce_result.stdout else reproduce_result.stderr
        print("   âœ… å†ç¾å®Œäº†ã€‚")
    except Exception as e:
        reproduce_output = f"å†ç¾ã‚¨ãƒ©ãƒ¼: {e}"
        print(f"[ã‚¨ãƒ©ãƒ¼] æ”»æ’ƒã®å†ç¾ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    try:
        print(f"\n3. åˆ†æçµæœã‚’ {ANALYSIS_FILE} ã«è¨˜éŒ²ä¸­...")
        analysis_record = {
            # â†“â†“â†“ ã“ã“ã‚’ä¿®æ­£ï¼ â†“â†“â†“
            "timestamp": datetime.now().isoformat(), # .isoformat() ã‚’ä»˜ã‘ã¦æ–‡å­—åˆ—ã«å¤‰æ›
            "original_log": log_data,
            "reproduction_result": reproduce_output.strip()
        }
        with open(ANALYSIS_FILE, "a") as f:
            f.write(json.dumps(analysis_record) + "\n")
        print("   âœ… è¨˜éŒ²å®Œäº†ã€‚")
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] çµæœã®è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    finally:
        if container_id:
            print("\n4. ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’ç ´æ£„ã—ã¾ã™ã€‚")
            subprocess.run(["docker", "stop", container_id], capture_output=True, text=True)

class ChangeHandler(FileSystemEventHandler):
    def __init__(self): self.last_positions = {}
    def on_modified(self, event):
        if event.is_directory or 'access.log' not in event.src_path: return
        filepath = event.src_path
        last_pos = self.last_positions.get(filepath, 0)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                f.seek(last_pos); new_lines = f.readlines(); self.last_positions[filepath] = f.tell()
            for line in new_lines:
                if not line.strip(): continue
                try:
                    log_data = parser(line)
                    if is_anomaly(log_data):
                        print("\nğŸš¨ğŸš¨ğŸš¨ ç•°å¸¸æ¤œçŸ¥ ğŸš¨ğŸš¨ğŸš¨"); pprint(log_data)
                        trigger_analysis_sequence(log_data)
                except ValueError: pass
        except Exception: pass

if __name__ == "__main__":
    print(f"--- ãƒ­ã‚°ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™ (Ctrl+Cã§çµ‚äº†) ---")
    event_handler = ChangeHandler(); observer = Observer()
    observer.schedule(event_handler, WATCH_DIR, recursive=True); observer.start()
    try:
        while True: time.sleep(1)
    except KeyboardInterrupt:
        observer.stop(); print("\n--- ç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™ ---")
    observer.join()