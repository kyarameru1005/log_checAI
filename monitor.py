import time
import joblib
import subprocess
import json
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import apache_log_parser
from pprint import pprint

# --- è¨­å®š ---
WATCH_DIR = "/var/log/apache2"
LOG_FORMAT = "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\""
parser = apache_log_parser.make_parser(LOG_FORMAT)
ANALYSIS_FILE = "analysis_results.jsonl"
IP_COUNTS_FILE = "ip_access_counts.json" # â˜…â˜…â˜… IPã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ« â˜…â˜…â˜…

class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime): return obj.isoformat()
        return super().default(obj)

# --- å¤–éƒ¨ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ ---
def load_list_from_file(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        return []

WHITELIST_PATTERNS = load_list_from_file('whitelist.txt')
BLACKLIST_PATTERNS = load_list_from_file('blacklist.txt')

# --- AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
try:
    model = joblib.load('log_anomaly_model.joblib')
    vectorizer = joblib.load('tfidf_vectorizer.joblib')
except FileNotFoundError:
    print("[ã‚¨ãƒ©ãƒ¼] AIãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    exit()

# (æ¤œçŸ¥é–¢æ•°ã‚„åˆ†æã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
def is_whitelisted(request_line): # ...
def is_blacklisted(request_line): # ...
def predict_log_anomaly(log_text): # ...
def trigger_analysis_sequence(log_data, detection_method): #...

# --- â˜…â˜…â˜… IPã‚«ã‚¦ãƒ³ãƒˆæ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸãƒãƒ³ãƒ‰ãƒ© â˜…â˜…â˜… ---
class ChangeHandler(FileSystemEventHandler):
    def __init__(self, state, ip_counts):
        self.last_positions = {}
        self.state = state
        self.ip_counts = ip_counts # IPã‚«ã‚¦ãƒ³ãƒˆç”¨ã®è¾æ›¸ã‚’å—ã‘å–ã‚‹

    def on_modified(self, event):
        if event.is_directory or 'access.log' not in event.src_path: return
        new_lines = []
        try:
            with open(event.src_path, 'r', encoding='utf-8') as f:
                f.seek(self.last_positions.get(event.src_path, 0))
                new_lines = f.readlines()
                self.last_positions[event.src_path] = f.tell()
        except Exception: return

        for line in new_lines:
            if not line.strip(): continue
            try:
                log_data = parser(line)
                request_line = log_data.get('request_first_line', '')
                
                # --- â˜…â˜…â˜… IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ— â˜…â˜…â˜… ---
                ip_address = log_data.get('remote_host')
                if ip_address:
                    self.ip_counts[ip_address] = self.ip_counts.get(ip_address, 0) + 1
                
                # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã‚’æœ€å„ªå…ˆã§ãƒã‚§ãƒƒã‚¯
                if is_whitelisted(request_line):
                    self.state['last_message_time'] = datetime.now()
                    continue

                # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã¨AIã§ç•°å¸¸ã‚’æ¤œçŸ¥
                is_detected, detection_method = False, ""
                if is_blacklisted(request_line):
                    is_detected, detection_method = True, "ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ"
                elif predict_log_anomaly(request_line):
                    is_detected, detection_method = True, "AI"

                if is_detected:
                    utc_time = log_data.get('time_received_datetimeobj')
                    log_time_str = utc_time.replace(tzinfo=timezone.utc).astimezone(ZoneInfo("Asia/Tokyo")).strftime('%Y-%m-%d %H:%M:%S') if utc_time else "æ™‚åˆ»ä¸æ˜"
                    
                    print(f"\nğŸš¨ğŸš¨ğŸš¨ã€{detection_method}ã§ç•°å¸¸ã‚’æ¤œçŸ¥ã€‘ğŸš¨ğŸš¨ğŸš¨")
                    print(f"ç™ºç”Ÿæ™‚åˆ» (JST): {log_time_str}")
                    pprint(log_data)
                    
                    self.state['last_message_time'] = datetime.now()
                    trigger_analysis_sequence(log_data, detection_method)
            except Exception as e:
                print(f"[è­¦å‘Š] ãƒ­ã‚°1è¡Œã®å‡¦ç†ã«å¤±æ•—: {e}")

if __name__ == "__main__":
    print("\n--- TwinAI - Log Sentinel (v2.2 IPã‚«ã‚¦ãƒ³ãƒˆç‰ˆ) èµ·å‹• ---")

    # --- â˜…â˜…â˜… èµ·å‹•æ™‚ã«IPã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ â˜…â˜…â˜… ---
    ip_counts_data = {}
    try:
        with open(IP_COUNTS_FILE, 'r', encoding='utf-8') as f:
            ip_counts_data = json.load(f)
        print(f"--- éå»ã®IPã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ---")
    except (FileNotFoundError, json.JSONDecodeError):
        print(f"--- IPã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ–°è¦ã«ä½œæˆã—ã¾ã™ ---")

    shared_state = { "last_message_time": datetime.now() }
    event_handler = ChangeHandler(shared_state, ip_counts_data)
    observer = Observer()
    observer.schedule(event_handler, WATCH_DIR, recursive=True)
    observer.start()
    
    print("--- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™ (Ctrl+Cã§çµ‚äº†) ---")

    try:
        while True:
            time.sleep(1)
            elapsed = (datetime.now() - shared_state["last_message_time"]).total_seconds()
            if elapsed > 60:
                jst_now = datetime.now(ZoneInfo("Asia/Tokyo")).strftime('%H:%M:%S')
                print(f"âœ… [ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸] {jst_now}ç¾åœ¨ã€æ–°ãŸãªç•°å¸¸ã¯æ¤œçŸ¥ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                shared_state["last_message_time"] = datetime.now()
                # --- â˜…â˜…â˜… å®šæœŸçš„ã«IPã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿å­˜ï¼ˆä»»æ„ï¼‰ â˜…â˜…â˜… ---
                with open(IP_COUNTS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(ip_counts_data, f, indent=4)

    except KeyboardInterrupt:
        print("\n--- ç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™ã€‚æœ€çµ‚çµæœã‚’ä¿å­˜ä¸­... ---")
    finally:
        # --- â˜…â˜…â˜… çµ‚äº†æ™‚ã«æœ€çµ‚çš„ãªIPã‚«ã‚¦ãƒ³ãƒˆã‚’ä¿å­˜ â˜…â˜…â˜… ---
        with open(IP_COUNTS_FILE, 'w', encoding='utf-8') as f:
            # ã‚¢ã‚¯ã‚»ã‚¹å›æ•°ãŒå¤šã„é †ã«ä¸¦ã³æ›¿ãˆã¦ä¿å­˜
            sorted_counts = dict(sorted(ip_counts_data.items(), key=lambda item: item[1], reverse=True))
            json.dump(sorted_counts, f, indent=4)
        print("--- IPã‚¢ã‚¯ã‚»ã‚¹å›æ•°ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ ---")
        observer.stop()
        
    observer.join()